policy:
  _target_: quest.algos.diffusion_policy.DiffusionPolicy
  diffusion_model:
    _target_: quest.algos.diffusion_policy.DiffusionModel
    noise_scheduler: 
      _target_: diffusers.schedulers.scheduling_ddim.DDIMScheduler
      num_train_timesteps: ${algo.num_train_timesteps}
      beta_schedule: squaredcos_cap_v2
    action_dim: ${task.shape_meta.action_dim}
    global_cond_dim: ${eval:'${algo.cat_obs_dim} + ${algo.lang_emb_dim}'}
    diffusion_step_emb_dim: ${task.diffusion_step_emb_dim}
    down_dims: [256,512,1024]
    ema_power: 0.75
    device: ${device}
  image_encoder_factory:
    _target_: quest.algos.utils.rgb_modules.ResnetEncoder
    _partial_: true
    input_shape: ${task.shape_meta.image_shape}
    output_size: ${algo.obs_emb_dim}
    pretrained: false
    freeze: false
    remove_layer_num: 4
    no_stride: false
    language_fusion: 'none'
  proprio_encoder:
    _target_: quest.algos.utils.mlp_proj.MLPProj
    input_size: ${task.shape_meta.proprio_dim}
    output_size: ${algo.proprio_emb_dim}
    num_layers: 1
  obs_proj:
    _target_: torch.nn.Identity
  task_encoder:
    _target_: torch.nn.Embedding
    num_embeddings: ${task.n_tasks}
    embedding_dim: ${algo.gpt_hidden_dim}
  # TODO: this assumes that all images have the same shape
  image_aug:
    _target_: quest.algos.utils.data_augmentation.DataAugGroup
    aug_list:
      - _target_: quest.algos.utils.data_augmentation.BatchWiseImgColorJitterAug
        input_shape: ${task.shape_meta.image_shape}
        brightness: 0.3
        contrast: 0.3
        saturation: 0.3
        hue: 0.3
        epsilon: 0.1
      - _target_: quest.algos.utils.data_augmentation.TranslationAug
        input_shape: ${task.shape_meta.image_shape}
        translation: 4
  optimizer_factory:
    _target_: torch.optim.AdamW
    _partial_: true
    lr: ${algo.lr}
    betas: [0.9, 0.999]    
    weight_decay: ${algo.weight_decay}
  scheduler_factory:
    _target_: torch.optim.lr_scheduler.CosineAnnealingLR
    _partial_: true
    eta_min: 1e-5
    last_epoch: -1
    T_max: ${training.n_epochs}





name: diffusion_policy

proprio_emb_dim: 128
obs_emb_dim: 256 # from resnet_out_dim to this value using MLP
diffusion_step_emb_dim: 256
lang_emb_dim: 256 # clip embedding size
cat_obs_dim: ${eval:'${algo.obs_emb_dim} + ${algo.proprio_emb_dim}'}

skill_block_size: 16 # this is input sequence length to encoder


diffusion_train_steps: 100
diffusion_inf_steps: 10

action_horizon: 2 # mpc horizon for execution
