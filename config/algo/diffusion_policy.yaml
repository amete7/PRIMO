policy:
  _target_: quest.algos.diffusion_policy.DiffusionPolicy
  diffusion_model:
    _target_: quest.algos.diffusion_policy.DiffusionModel
    noise_scheduler: 
      _target_: diffusers.schedulers.scheduling_ddim.DDIMScheduler
      num_train_timesteps: ${algo.diffusion_train_steps}
      beta_schedule: squaredcos_cap_v2
    action_dim: ${task.shape_meta.action_dim}
    global_cond_dim: ${eval:'${algo.cat_obs_dim} + ${algo.lang_emb_dim}'}
    diffusion_step_emb_dim: ${algo.diffusion_step_emb_dim}
    down_dims: [256,512,1024]
    ema_power: 0.75
    skill_block_size: ${algo.skill_block_size}
    diffusion_inf_steps: ${algo.diffusion_inf_steps}
    device: ${device}
  image_encoder_factory:
    _target_: quest.algos.utils.rgb_modules.ResnetEncoder
    _partial_: true
    output_size: ${algo.obs_emb_dim}
    pretrained: false
    freeze: false
    remove_layer_num: 4
    no_stride: false
    language_fusion: 'none'
  pointcloud_encoder_factory: null
  lowdim_encoder_factory:
    _target_: quest.algos.utils.mlp_proj.MLPProj
    _partial_: true
    output_size: ${algo.proprio_emb_dim}
    num_layers: 1
  obs_proj:
    _target_: torch.nn.Identity
  task_encoder:
    _target_: torch.nn.Embedding
    num_embeddings: ${task.n_tasks}
    embedding_dim: ${algo.lang_emb_dim}
  # TODO: this assumes that all images have the same shape
  image_aug_factory:
    _target_: quest.algos.utils.data_augmentation.DataAugGroup
    _partial_: true
    aug_list:
      - _target_: quest.algos.utils.data_augmentation.BatchWiseImgColorJitterAug
        _partial_: true
        brightness: 0.3
        contrast: 0.3
        saturation: 0.3
        hue: 0.3
        epsilon: 0.1
      - _target_: quest.algos.utils.data_augmentation.TranslationAug
        _partial_: true
        translation: 4
  aug_factory: null
  optimizer_factory:
    _target_: torch.optim.AdamW
    _partial_: true
    lr: ${algo.lr}
    betas: [0.9, 0.999]    
    weight_decay: ${algo.weight_decay}
  scheduler_factory:
    _target_: torch.optim.lr_scheduler.CosineAnnealingLR
    _partial_: true
    eta_min: 1e-5
    last_epoch: -1
    T_max: ${training.n_epochs}
  action_horizon: ${algo.action_horizon}
  device: ${device}





name: diffusion_policy

lr: 0.0001
weight_decay: 0.0001

proprio_emb_dim: 128
obs_emb_dim: 256 # from resnet_out_dim to this value using MLP
diffusion_step_emb_dim: 256
lang_emb_dim: 256 # clip embedding size
cat_obs_dim: ${eval:'${algo.obs_emb_dim} + ${algo.proprio_emb_dim}'}

skill_block_size: 16 # this is input sequence length to encoder


diffusion_train_steps: 100
diffusion_inf_steps: 10

action_horizon: 2 # mpc horizon for execution

frame_stack: 1

dataset:
  seq_len: ${algo.skill_block_size}
  frame_stack: ${algo.frame_stack}
  obs_seq_len: 1
  load_obs_for_pretrain: true
