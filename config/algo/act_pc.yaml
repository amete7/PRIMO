policy:
  _target_: quest.algos.act.ACT
  act_model:
    _target_: quest.algos.baseline_modules.act_utils.detr_vae.DETRVAE
    # backbones:
    #   _target_: quest.algos.baseline_modules.act_utils.backbone.build_backbone
    #   position_embedding_type: "sine"
    #   hidden_dim: ${algo.embed_dim}
    #   backbone_type: "resnet18"
    #   lr_backbone: ${algo.lr}
    #   masks: false
    #   dilation: false
    transformer:
      _target_: quest.algos.baseline_modules.act_utils.transformer.build_transformer
      hidden_dim: ${algo.embed_dim}
      dropout: 0.1
      nheads: 8
      dim_feedforward: ${eval:'${algo.embed_dim} * 4'}
      enc_layers: 4
      dec_layers: 7
      pre_norm: false
    encoder:
      _target_: quest.algos.baseline_modules.act_utils.detr_vae.build_encoder
      d_model: ${algo.embed_dim}
      nheads: 8
      dim_feedforward: ${eval:'${algo.embed_dim} * 4'}
      enc_layers: 4
      pre_norm: false
      dropout: 0.1
    state_dim: ${task.shape_meta.action_dim}
    proprio_dim: 8
    num_queries: ${algo.skill_block_size}
    encoder_input: [lowdim, perception]
  image_encoder_factory: null
  pointcloud_encoder_factory:
    _target_: quest.algos.utils.pointnet_extractor.PointNetEncoder
    _partial_: true
    out_channels: ${algo.embed_dim}
    use_layernorm: false
    final_norm: "none"
    block_channel: [64, 128, 256, 512]
  lowdim_encoder_factory: 
    _target_: quest.algos.utils.mlp_proj.MLPProj
    _partial_: true
    output_size: ${algo.embed_dim}
    num_layers: 1
  obs_proj: null
  task_encoder:
    _target_: torch.nn.Embedding
    num_embeddings: ${task.n_tasks}
    embedding_dim: ${algo.embed_dim}
  # TODO: this assumes that all images have the same shape
  image_aug_factory: null
  aug_factory: 
    _target_: quest.algos.utils.data_augmentation.MetaworldPointcloudRotationAug
    _partial_: true
  optimizer_factory:
    _target_: torch.optim.AdamW
    _partial_: true
    lr: ${algo.lr}
    betas: [0.9, 0.999]    
    weight_decay: ${algo.weight_decay}
  scheduler_factory:
    _target_: torch.optim.lr_scheduler.CosineAnnealingLR
    _partial_: true
    eta_min: 1e-5
    last_epoch: -1
    T_max: ${training.n_epochs}
  loss_fn:
    _target_: torch.nn.L1Loss
  kl_weight: ${algo.kl_weight}
  lr_backbone: ${algo.lr}
  shape_meta: ${task.shape_meta}
  action_horizon: ${algo.action_horizon}
  device: ${device}

name: act

lr: 0.0001
weight_decay: 0.0001

kl_weight: 10.0
embed_dim: 512
action_horizon: 2

skill_block_size: 16 # this is output action sequence length
frame_stack: 1 # this is input observation sequence length

dataset:
  seq_len: ${algo.skill_block_size}
  frame_stack: ${algo.frame_stack}
  obs_seq_len: 1
  load_obs_for_pretrain: true