defaults:
  - base
  - _self_

policy:
  _target_: quest.algos.bc_transformer.BCTransformerPolicy
  transformer_model:
    _target_: quest.algos.baseline_modules.bc_transformer_modules.TransformerDecoder
    input_size: ${algo.embed_dim}
    num_layers: 4
    num_heads: 6
    head_output_size: 64
    mlp_hidden_size: 256
    dropout: 0.1
  policy_head:
    _target_: quest.algos.baseline_modules.bc_transformer_modules.GMMHead
    input_size: ${algo.embed_dim}
    output_size: ${task.shape_meta.action_dim}
    hidden_size: 1024
    num_layers: 2
    min_std: 0.0001
    num_modes: 5
    low_eval_noise: false
    activation: "softplus"
    loss_coef: 1.0
  positional_encoding:
    _target_: quest.algos.baseline_modules.bc_transformer_modules.SinusoidalPositionEncoding
    input_size: ${algo.embed_dim}
    inv_freq_factor: 10
  image_encoder_factory:
    _target_: quest.algos.utils.rgb_modules.ResnetEncoder
    _partial_: true
    output_size: ${algo.embed_dim}
    pretrained: false
    freeze: false
    remove_layer_num: 4
    no_stride: false
    language_fusion: 'none'
  lowdim_encoder_factory:
    _target_: quest.algos.utils.mlp_proj.MLPProj
    _partial_: true
    output_size: ${algo.embed_dim}
    num_layers: 1
  obs_proj:
    _target_: torch.nn.Identity
  task_encoder:
    task_embedding_type: ${algo.task_embedding_type}
    num_embeddings: ${task.n_tasks}
    embedding_dim: ${algo.embed_dim}
    input_dim: 512 # clip embedding dim
  # TODO: this assumes that all images have the same shape
  image_aug_factory:
    _target_: quest.algos.utils.data_augmentation.DataAugGroup
    _partial_: true
    aug_list:
      - _target_: quest.algos.utils.data_augmentation.BatchWiseImgColorJitterAug
        _partial_: true
        brightness: 0.3
        contrast: 0.3
        saturation: 0.3
        hue: 0.3
        epsilon: 0.1
      - _target_: quest.algos.utils.data_augmentation.TranslationAug
        _partial_: true
        translation: 4
  optimizer_factory:
    _target_: torch.optim.AdamW
    _partial_: true
    lr: ${algo.lr}
    betas: [0.9, 0.999]    
    weight_decay: ${algo.weight_decay}
  scheduler_factory:
    _target_: torch.optim.lr_scheduler.CosineAnnealingLR
    _partial_: true
    eta_min: 1e-5
    last_epoch: -1
    T_max: ${training.n_epochs}
  shape_meta: ${task.shape_meta}
  reduction: 'mean'
  device: ${device}

name: bc_transformer_policy

lr: 0.0001
weight_decay: 0.0001

embed_dim: 64
skill_block_size: 1 # this is output action sequence length
frame_stack: 10 # this is input observation sequence length

dataset:
  seq_len: ${algo.skill_block_size}
  frame_stack: ${algo.frame_stack}
  obs_seq_len: 1
  load_obs_for_pretrain: false