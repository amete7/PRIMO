policy:
  _target_: quest.algos.act_policy.ACTPolicy
  act_model:
    _target_: quest.algos.baseline_modules.act_utils.detr_vae.DETRVAE
    backbones:
      _target_: quest.algos.baseline_modules.act_utils.backbone.build_backbone
      position_embedding_type: "sine"
      hidden_dim: ${algo.embed_dim}
      backbone_type: "resnet18"
      lr_backbone: ${algo.lr}
      masks: false
      dilation: false
    transformer:
      _target_: quest.algos.baseline_modules.act_utils.transformer.build_transformer
      hidden_dim: ${algo.embed_dim}
      dropout: 0.1
      nheads: 8
      dim_feedforward: ${eval:'${algo.embed_dim} * 4'}
      enc_layers: 4
      dec_layers: 7
      pre_norm: false
    encoder:
      _target_: quest.algos.baseline_modules.act_utils.detr_vae.build_encoder
      d_model: ${algo.embed_dim}
      nheads: 8
      dim_feedforward: ${eval:'${algo.embed_dim} * 4'}
      enc_layers: 4
      pre_norm: false
      dropout: 0.1
    state_dim: ${task.shape_meta.action_dim}
    proprio_dim: ${task.shape_meta.proprio_dim}
    num_queries: ${algo.skill_block_size}
    camera_names: ${task.shape_meta.image_inputs}
  image_encoder_factory: null
  proprio_encoder: null
  obs_proj: null
  task_encoder:
    _target_: torch.nn.Embedding
    num_embeddings: ${task.n_tasks}
    embedding_dim: ${algo.embed_dim}
  # TODO: this assumes that all images have the same shape
  image_aug:
    _target_: quest.algos.utils.data_augmentation.DataAugGroup
    aug_list:
      - _target_: quest.algos.utils.data_augmentation.BatchWiseImgColorJitterAug
        input_shape: ${task.shape_meta.image_shape}
        brightness: 0.3
        contrast: 0.3
        saturation: 0.3
        hue: 0.3
        epsilon: 0.1
      - _target_: quest.algos.utils.data_augmentation.TranslationAug
        input_shape: ${task.shape_meta.image_shape}
        translation: 4
  optimizer_factory:
    _target_: torch.optim.AdamW
    _partial_: true
    lr: ${algo.lr}
    betas: [0.9, 0.999]    
    weight_decay: ${algo.weight_decay}
  scheduler_factory:
    _target_: torch.optim.lr_scheduler.CosineAnnealingLR
    _partial_: true
    eta_min: 1e-5
    last_epoch: -1
    T_max: ${training.n_epochs}
  loss_fn:
    _target_: torch.nn.L1Loss
  kl_weight: ${algo.kl_weight}
  lr_backbone: ${algo.lr}
  shape_meta: ${task.shape_meta}
  action_horizon: ${algo.action_horizon}
  device: ${device}

name: act_policy

lr: 0.0001
weight_decay: 0.0001

kl_weight: 10.0
embed_dim: 512
action_horizon: 2

skill_block_size: 16 # this is output action sequence length
frame_stack: 1 # this is input observation sequence length
