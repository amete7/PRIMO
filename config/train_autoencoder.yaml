# @package _global_

defaults:
  - task: metaworld_ml45
  - algo: quest
  - _self_

# Override frame stack to be zero so we don't load a bunch of past observations we don't need
task:
  frame_stack: 1

train_dataloader:
  _target_: torch.utils.data.DataLoader
  batch_size: 256
  shuffle: true
  num_workers: 6
  persistent_workers: false
  pin_memory: true
  # prefetch_factor: 2
  # multiprocessing_context: fork

training:
  # training
  n_epochs: 1000
  grad_clip: 100.
  save_interval: 10
  log_interval: 100
  use_amp: false # this seems to cause instabilities for shorter chunks (<64) but causes speedups for larger ones
  use_tqdm: true
  do_profile: False
  save_all_checkpoints: false
  auto_continue: false # if true, it will automatically continue from the end of stage n training for stage n+1 training
  load_obs: false

  # resume training
  resume: false
  resume_path: ""

rollout:
  enabled: false
  rollouts_per_env: null
  max_episode_length: null

logging:
  group: null
  mode: online # set logging.mode=disabled to disable wandb
  project: skill-metaworld
  resume: true
  save_code: true



exp_name: debug # 
variant_name: null
seed: 10000
device: cuda:0
stage: 0 # 0 - pretrain autoencoder, 1 - train multitask, 2 - finetune multitask
output_prefix: ./experiments
data_prefix: ./data
make_unique_experiment_dir: true

checkpoint_path: null



